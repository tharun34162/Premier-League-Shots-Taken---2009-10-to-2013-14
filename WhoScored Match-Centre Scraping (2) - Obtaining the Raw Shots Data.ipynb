{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhoScorred Match-Centre Scraping - Part 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I shall be scraping the shots data from each of WhoScored match URLs I had scraped earlier. Essentially, I run a loop function which goes through each & every match URL in the excel file and picks out just the shots data that I want. \n",
    "\n",
    "I want to give a massive massive shout-out to the Github User [Ali Hasan Khan](https://github.com/Ali-Hasan-Khan/Scrape-Whoscored-Event-Data) because it is primiarly his code that I have tweaked for my benefit. There is a separate python scripts of his that is used in this notebook called \"main\" which should be attached along with the notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium import webdriver\n",
    "import main\n",
    "import seaborn as sns\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Please import the excel file named 'PL 2013-14 -- WhoScored Match URLs' under the name \"match_urls\"\n",
    "\n",
    "season = '2013-14.xlsx'\n",
    "\n",
    "import_folder_path = 'C:/Users/tharu/OneDrive/Desktop/Big-PL-Project/PL-Project/WhoScored Match URLs/Final/Premier League' \n",
    "import_file_path = f\"{import_folder_path}/{season}\"\n",
    "\n",
    "export_folder_path = 'C:/Users/tharu/OneDrive/Desktop/Big-PL-Project/PL-Project/WhoScored Shots Data - Raw/Premier League' \n",
    "\n",
    "match_urls = pd.read_excel(import_file_path)\n",
    "match_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Picking out the attributes from WhoScored I would like to have for each & every shot I scrape\n",
    "\n",
    "final_df = pd.DataFrame(columns=['minute', 'second', 'expandedMinute',\n",
    "   'teamId', 'h_a', 'x', 'y','period','type', 'playerId','playerName',\n",
    "   'relatedPlayerId','blockedX', 'blockedY','goalMouthZ','goalMouthY', 'isGoal', \n",
    "   'shotBodyType','situation', 'shotSixYardBox', 'shotPenaltyArea', 'shotOboxTotal',\n",
    "   'shotOpenPlay', 'shotCounter', 'shotSetPiece', 'shotDirectCorner',                 \n",
    "   'shotOffTarget','shotOnPost','shotOnTarget','shotBlocked','goalOwn',             \n",
    "   'bigChanceMissed','bigChanceScored','bigChanceCreated',\n",
    "   'penaltyScored','penaltyMissed',\n",
    "   'penaltyShootoutScored', 'penaltyShootoutMissedOffTarget', 'penaltyShootoutSaved', \n",
    "    'start_date', 'home_teamId', 'away_teamId', 'matchId', 'season', 'match_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Please ensure you have the correct chromedriver application! If not, download it \n",
    "### Be ready to wait haha; It will take at least two & a half hours at the very least\n",
    "### for this loop function to go through all 380 match URLs.\n",
    "\n",
    "for i in range(len(match_urls)):\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        service = Service(executable_path=r'C:\\\\Users\\\\tharu\\\\OneDrive\\\\Desktop\\\\Big-PL-Project\\\\PL-Project\\\\chromedriver.exe')\n",
    "        options = webdriver.ChromeOptions()\n",
    "        driver = webdriver.Chrome(service=service, options=options)   \n",
    "    \n",
    "    # whoscored match centre url of the required match\n",
    "    url = match_urls['Links'][i]\n",
    "    match_data = main.getMatchData(driver, url)\n",
    "\n",
    "    # Match dataframe containing info about the match\n",
    "    matches_df = main.createMatchesDF(match_data)\n",
    "\n",
    "    # Events dataframe   \n",
    "    events_df = main.createEventsDF(match_data)\n",
    "    shots = events_df.query('isShot == True')\n",
    "    \n",
    "    shots_df = shots[['minute', 'second', 'expandedMinute',\n",
    "   'teamId', 'h_a', 'x', 'y','period','type', 'playerId','playerName',\n",
    "   'relatedPlayerId','blockedX', 'blockedY','goalMouthZ','goalMouthY', 'isGoal', \n",
    "   'shotBodyType','situation', 'shotSixYardBox', 'shotPenaltyArea', 'shotOboxTotal',\n",
    "   'shotOpenPlay', 'shotCounter', 'shotSetPiece', 'shotDirectCorner',                 \n",
    "   'shotOffTarget','shotOnPost','shotOnTarget','shotBlocked','goalOwn',             \n",
    "   'bigChanceMissed','bigChanceScored','bigChanceCreated',\n",
    "   'penaltyScored','penaltyMissed',\n",
    "   'penaltyShootoutScored', 'penaltyShootoutMissedOffTarget', 'penaltyShootoutSaved']]\n",
    "    \n",
    "    \n",
    "    start_date = datetime.strptime(matches_df.iloc[0, matches_df.columns.get_loc('startDate')].split(\"T\")[0],'%Y-%m-%d').date()\n",
    "    home_teamId = int(re.findall(r'\\d+', str(matches_df.iloc[0, matches_df.columns.get_loc('home')]).split(\",\")[0])[0])\n",
    "    away_teamId = int(re.findall(r'\\d+', str(matches_df.iloc[0, matches_df.columns.get_loc('away')]).split(\",\")[0])[0])\n",
    "    matchId = int(re.findall(r'\\d+', str(events_df.iloc[0, events_df.columns.get_loc('matchId')]).split(\",\")[0])[0])\n",
    "\n",
    "    shots_df['start_date'] = start_date\n",
    "    shots_df['home_teamId'] = home_teamId\n",
    "    shots_df['away_teamId'] = away_teamId\n",
    "    shots_df['matchId'] = matchId\n",
    "    shots_df['match_count'] = i\n",
    "\n",
    "    Players = events_df.drop_duplicates(['playerId','playerName'])[['playerId','playerName']].dropna()\n",
    "    Players = Players.rename(columns={'playerId': 'relatedPlayerId', 'playerName': 'relatedplayerName'})\n",
    "    Players['relatedPlayerId'] = Players['relatedPlayerId'].astype(float)\n",
    "\n",
    "    shots_df_final = shots_df.merge(Players, on='relatedPlayerId', how='left')\n",
    "    final_df = pd.concat([final_df, shots_df_final], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exporting the raw shots data to the folder of choice\n",
    "final_df.to_excel(os.path.join(export_folder_path, season), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
